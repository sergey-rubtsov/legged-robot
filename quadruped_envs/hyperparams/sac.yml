# To be tuned
OpenDynamicQuadrupedEnv-v0:
  normalize: "{'norm_obs': True, 'norm_reward': False}"
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  learning_rate: lin_3e-4
  buffer_size: 1000000
  batch_size: 64
  ent_coef: 'auto'
  # ent_coef: 0.0003
  train_freq: 1
  gradient_steps: 1
  learning_starts: 1000

OpenDynamicImitationEnv-v0:
  normalize: "{'norm_obs': True, 'norm_reward': False}"
  n_timesteps: !!float 2e7
  policy: 'MlpPolicy'
  learning_rate: lin_3e-4
  buffer_size: 1000000
  batch_size: 32768
  ent_coef: 'auto'
  train_freq: 1
  gradient_steps: 1
  learning_starts: 1000

HumanoidDeepMimicWalkBulletEnv-v1:
  normalize: "{'norm_obs': True, 'norm_reward': False}"
  n_timesteps: !!float 2e7
  policy: 'MlpPolicy'
  learning_rate: lin_3e-4
  buffer_size: 1000000
  batch_size: 64
  ent_coef: 'auto'
  train_freq: 1
  gradient_steps: 1
  learning_starts: 1000

HumanoidBulletEnv-v0:
  normalize: "{'norm_obs': True, 'norm_reward': False}"
  n_timesteps: !!float 2e7
  policy: 'MlpPolicy'
  learning_rate: lin_3e-4
  buffer_size: 1000000
  batch_size: 64
  ent_coef: 'auto'
  train_freq: 1
  gradient_steps: 1
  learning_starts: 1000